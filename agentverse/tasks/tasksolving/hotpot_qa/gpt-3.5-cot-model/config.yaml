cnt_agents: &cnt_agents 3
max_turn: &max_turn 1
max_criticizing_rounds: 0

prompts:
  role_assigner_prepend_prompt: &role_assigner_prepend_prompt |-

  role_assigner_append_prompt: &role_assigner_append_prompt |-
    Generate a list of ${cnt_critic_agents} names. Here is an example of your response:
    EXAMPLE:
    1. Alice
    2. Bob
    3. Charli
    ...
# You are the leader of a group, now you are facing a problem:
# ```
# ${task_description}
# ```

# You can recruit ${cnt_critic_agents} people to solve the logic problem. What people will you recruit?

# Here are some suggestion:
# ${advice}

# ## Response Format Guidance
# You should respond with a list of expert names. For example:
# 1. Alice
# 2. Bob
# 3. Charlie
# ...

# Only respond with the names. Do not include your reason.

  solver_prepend_prompt: &solver_prepend_prompt |-


  # Messages from the solver and critics will be filled here in the code.
  
  solver_append_prompt: &solver_append_prompt |-
    ${task_description}

    At the end of your response, you must give your answer in the form of "the answer is: {number}", where {number} is the answer number. Now solve the problem step-by-step.

# Using these information, can you provide the correct solution to the math problem? Explain your reasoning and solve the problem step by step. Your final answer should be a single integer, which is the number of choice, in the form \boxed{answer}, at the end of your response.

  critic_prepend_prompt: &critic_prepend_prompt |-
    You are ${agent_name}. Together with ${all_roles}, you are providing accurate answer to the user. Each of you will be provided parts of the contexts and a shared question. 

    EXAMPLE 1
    ---
    # Context
    - **Arthur's Magazine**. Arthur's Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century. Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others. In May 1846 it was merged into "Godey's Lady's Book".
    - **First for Women**. First for Women is a woman's magazine published by Bauer Media Group in the USA. The magazine was started in 1989. It is based in Englewood Cliffs, New Jersey. In 2011 the circulation of the magazine was 1,310,696 copies.
    - ...

    # Question
    Which magazine was started first Arthur's Magazine or First for Women?
    ---
    The answer is "Arthur's Magazine".

    EXAMPLE 2
    ---
    # Context
    - The 2014-15 Ukrainian Hockey Championship was the 23rd season of the Ukrainian Hockey Championship. Only four teams participated in the league this season, because of the instability in Ukraine and that most of the clubs had economical issues. Generals Kiev was the only team that participated in the league the previous season, and the season started first after the year-end of 2014. The regular season included just 12 rounds, where all the teams went to the semifinals. In the final, ATEK Kiev defeated the regular season winner HK Kremenchuk.
    - ...(other unrelevant contexts)

    # Question
    Which magazine was started first Arthur's Magazine or First for Women?
    ---
    You don't have relevant context on the question, so you need to communication with others.

    Now the user gives you some contexts and the question:
    ---
    # Context
    ${knowledge}

    # Question
    ${task_description}
    ---

  critic_append_prompt: &critic_append_prompt |-
    Given that each individual, including yourself, possesses unique contexts, your specific context is unknown to others unless explicitly communicated. 

    You are ${agent_name}, collaborating with ${all_roles}, who are also intelligent assistants. Your goal is to provide a clear and concise answer to the user's question. Unlike typical communication, you will not use natural language, as it often contains ambiguities and emotional nuances. Instead, choose a more straightforward and precise communication medium, such as structured data, JSON, XML or code.

    Now, start communicating with ${all_roles} using your selected non-natural language medium. Remember, clarity and brevity are key.

    IMPORTANT: Once you have formulated the final answer to the question, enclose it within "Answer: {xxx}", where "xxx" represents the answer phrase. The conversation concludes when all participants have presented their responses in this format.

    REMEMBER:
    Do not always repeat what others have said, as well as what you have said yourself. 
    Remember to use Answer: {xxx} when you believe you have arrived at the final answer, where xxx is your response to the question.
  evaluator_prepend_prompt: &evaluator_prepend_prompt |-
    Problem:
    ```
    ${task_description}
    ```

    Solution: 
    ```
    ${solution}
    ```

    You are a logic problem lover. Above is a logic problem and a solution. Check whether the solution and the deduction is correct. If the deduction is wrong, you should explain why it is wrong, but do not give your solution. When it is correct, output a correctness of 1 and why it is correct.
    
  evaluator_append_prompt: &evaluator_append_prompt |-
    You should respond in the following format:
    Correctness: (0 or 1, 0 is wrong, and 1 is correct)
    Response: (explain in details why it is wrong or correct. do not provide your solution)

    


name: pipeline


environment:
  env_type: task-basic
  max_turn: *max_turn
  rule:
    role_assigner:
      type: role_description
      cnt_agents: *cnt_agents
    decision_maker:
      type: debate
      max_turns: 8
    executor:
      type: none
    evaluator:
      type: dummy-true

agents:
  - #role_assigner_agent:
    agent_type: role_assigner
    name: role assigner
    max_retry: 1000
    prepend_prompt_template: *role_assigner_prepend_prompt
    append_prompt_template: *role_assigner_append_prompt
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: gpt-4-1106
      temperature: 0
      max_tokens: 512
    output_parser:
      type: role_assigner
      
  - #solver_agent:
    agent_type: solver
    name: Planner
    max_retry: 1000
    prepend_prompt_template: *solver_prepend_prompt
    append_prompt_template: *solver_append_prompt
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-3.5-turbo
      model: gpt-3.5-turbo-0301
      max_tokens: 1024
      temperature: 0
    output_parser:
      type: mgsm

  - #critic_agents:
    agent_type: critic
    name: Critic 1
    max_retry: 1000
    max_history: 20
    role_description: |-
      Waiting to be assigned.
    prepend_prompt_template: *critic_prepend_prompt
    append_prompt_template: *critic_append_prompt
    memory:
      memory_type: chat_history
      add_sender_prefix: false
      add_sender_in_message: true
    flatten: false
    llm:
      llm_type: gpt-3.5-turbo
      model: gpt-3.5-turbo-1106
      temperature: 0
    output_parser:
      type: qa-critic

  - #executor_agent:
    agent_type: executor
    name: Executor
    max_retry: 1000
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: gpt-4-1106
      temperature: 0
      max_tokens: 1024
    output_parser:
      type: mgsm

  - #evaluator_agent:
    agent_type: evaluator
    name: Evaluator
    max_retry: 1000
    role_description: |-
      Evaluator
    prepend_prompt_template: *evaluator_prepend_prompt
    append_prompt_template: *evaluator_append_prompt
    memory:
      memory_type: chat_history
    llm:
      llm_type: gpt-4
      model: gpt-4-1106
      temperature: 0.3
      max_tokens: 1024
    output_parser:
      type: mgsm-evaluator
      dimensions:
        - Correctness


tools:

